{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch work for EDA of axon fragment imaging\n",
    "\n",
    "As part of Mayoral lab investigation of oligodendrocyte precursor cell influence on neurodegenertation, have fluroescent images with channels:\n",
    "- GFP (sparse axonal labeling)\n",
    "- DegenoTag\n",
    "- Myelin staining\n",
    "- DAPI\n",
    "\n",
    "Goal is to development automated pipelines for assessing degree of degeration across different samples. Initial goal is to develop algorithms for detecting and statistically characterizing fragments of axons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import block\n",
    "\n",
    "# System\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# CSV Handling\n",
    "import csv\n",
    "\n",
    "# Image handling\n",
    "import tifffile as tf \n",
    "import imageio as img # tiff writing\n",
    "import czifile\n",
    "from tifffile import imsave, imread, imwrite\n",
    "\n",
    "# Numerical and statistics\n",
    "import seaborn as sb\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "from scipy.stats import mode\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Image analysis\n",
    "import cv2 as cv\n",
    "import skimage as sk\n",
    "from skimage import io, morphology\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import data\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Parsing Cell\n",
    "## The purpose of the cell below is to\n",
    "- Read the CSV Files\n",
    "- Parse the CSV Files\n",
    "- Extract statistical information from the fragment lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "roi_directory = 'data/ROI'\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(roi_directory) if f.endswith('.csv')]\n",
    "# Loop through each CSV file and read its contents\n",
    "total_lengths_array = []\n",
    "for csv_file in csv_files:\n",
    "  csv_lengths_array = []\n",
    "  file_path = os.path.join(roi_directory, csv_file)\n",
    "  with open(file_path, 'r') as file:\n",
    "      csvreader = csv.reader(file)\n",
    "      print(f\"Contents of {csv_file}:\")\n",
    "      header = next(csvreader)\n",
    "      for row in csvreader:\n",
    "        csv_lengths_array.append(row[5])\n",
    "      # print(row[5])\n",
    "      # print(csv_lengths_array)\n",
    "      numeric_values = [float(num) for num in csv_lengths_array]\n",
    "      print(numeric_values)\n",
    "      total_lengths_array.append(numeric_values)\n",
    "  print(\"\\n\")  # Add a newline for better readability between files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_sum = 0\n",
    "respective_sub_means = []\n",
    "for i in range(len(total_lengths_array)):\n",
    "    respective_sub_means.append(np.mean(total_lengths_array[i]))\n",
    "    \n",
    "\n",
    "# Flatten the list of arrays and calculate statistics\n",
    "all_lengths = np.concatenate([np.array(arr) for arr in total_lengths_array])\n",
    "\n",
    "# Mean, standard deviation, median, quantiles\n",
    "mean_all = np.mean(all_lengths)\n",
    "std_dev = np.std(all_lengths)\n",
    "median_all = np.median(all_lengths)\n",
    "quantiles = np.percentile(all_lengths, [25, 50, 75])\n",
    "print(f\"Individual sub-array means: {respective_sub_means}\")\n",
    "print(f\"Overall mean: {mean_all}\")\n",
    "print(f\"Standard deviation: {std_dev}\")\n",
    "print(f\"Median: {median_all}\")\n",
    "print(f\"Quantiles (25th, 50th, 75th): {quantiles}\")\n",
    "## find standard deviation, median, quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets the view mode of matplotlib\n",
    "if 1:\n",
    "    %matplotlib qt\n",
    "    plt.ion()\n",
    "else:\n",
    "    %matplotlib inline\n",
    "    plt.ion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing stage\n",
    " This section will do the following:\n",
    " - Convert CZI files to TIFF\n",
    " - Read the images into respective image arrays\n",
    " - Crop the image arrays to the respective region of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This cell takes in a particular input directory and output directory to convert the czi files to tiff files.\n",
    "'''\n",
    "\n",
    "main_directory = \"data\"\n",
    "input_directory = os.path.join(main_directory, \"czi_images_directory\")\n",
    "output_directory = os.path.join(main_directory, \"tiff_images_directory\")\n",
    "\n",
    "# Check if output directory exists, create if not\n",
    "if not os.path.exists(output_directory):\n",
    "    print(\"Output Directory not found, creating one \\n\")\n",
    "    os.makedirs(output_directory)\n",
    "    print(\"Output Directory successfully created \\n\")\n",
    "\n",
    "# Loop through files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    full_file_path = os.path.join(input_directory, filename)\n",
    "    \n",
    "    # Check if it is a file and has a .czi extension\n",
    "    if os.path.isfile(full_file_path) and filename.lower().endswith('.czi'):\n",
    "        with czifile.CziFile(full_file_path) as czi:\n",
    "            image_array = czi.asarray()\n",
    "        \n",
    "        # Save the image as TIFF in the output directory\n",
    "        output_file_path = os.path.join(output_directory, filename + '.tiff')\n",
    "        tf.imsave(output_file_path, image_array, imagej=True)\n",
    "        print(f\"Successfully converted: {filename} to {output_directory} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(channel_array):  \n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (channel_array which is ideally a channel of an array) \n",
    "        \n",
    "    This function:\n",
    "        Crops of the image to the specified x and y limits \n",
    "\n",
    "    This function returns:\n",
    "        a cropped 2D array\n",
    "    '''\n",
    "    x_min = 2200\n",
    "    x_max = 3200\n",
    "    y_min = 1100\n",
    "    y_max = 3000\n",
    "    return channel_array[y_min:y_max, x_min:x_max]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This array stores the information of the 2D arrays of the channel for statistical analysis\n",
    "channel_data_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_before_crop(image_array):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array) \n",
    "        \n",
    "    This function:\n",
    "        Flattens the 2D array and sorts it numerically\n",
    "\n",
    "    This function returns:\n",
    "        The flattened and sorted 1D array (sorted_pixel_values)\n",
    "    '''\n",
    "    pixel_values = image_array.flatten()\n",
    "    sorted_pixel_values = np.sort(pixel_values)\n",
    "    return sorted_pixel_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_channels(tiff_image):\n",
    "    ''' \n",
    "    This function takes in:\n",
    "        A image path to a tiff image (tiff_image)\n",
    "        \n",
    "    This function:\n",
    "        Reads the image, splits the image into its distinct channels and adds those arrays to an array of arrays.\n",
    "\n",
    "    This function returns:\n",
    "        An array of arrays (image_channel_arrays)\n",
    "        \n",
    "    ''' \n",
    "    image_array = tf.imread(tiff_image) #Gets the image array\n",
    "    image_channels_array = []\n",
    "    num_channels = image_array.shape[0] # Gets the number of channels\n",
    "    for channel in range(num_channels):\n",
    "        channel_data = image_array[channel]  # Extract data for one channel\n",
    "        channel_data_array.append(save_array_before_crop(channel_data))\n",
    "        image_channels_array.append(channel_data)\n",
    "    return image_channels_array\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This runs the command to splits the channels and saves them into the channels_directory\n",
    "array = split_channels('data/tiff_images_directory/CTRL_INT_4.czi.tiff')\n",
    "\n",
    "# Loop through the channels and save each one\n",
    "for i, channel in enumerate(array):\n",
    "    # Save the image using tifffile\n",
    "    tf.imwrite(os.path.join(\"data/channels_directory\", f'channel_{i+1}.tiff'), channel)\n",
    "\n",
    "## crops and saves the images to the directory\n",
    "cropped_array = [crop_image(channel) for channel in array]\n",
    "for j, cropped_channel in enumerate(cropped_array):\n",
    "    output_file_path = os.path.join(\"data/cropped_images\", \"cropped_image_channel_\" + str(j + 1) + \".tiff\")\n",
    "    tf.imsave(output_file_path, cropped_channel, imagej=True)\n",
    "    print(f\"Successfully saved cropped channel {j + 1} to {output_file_path} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin anaylsis\n",
    "\n",
    "In this code segment we will be doing the following:\n",
    "- Defining the threshhold of for the image\n",
    "- Reconstructing the image (WIP)\n",
    "- Removing noise and skeletizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_of_image(image_array): \n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array)\n",
    "    This function:\n",
    "        Performs a morphological reconstruction of the 2D array\n",
    "    This function returns:\n",
    "        A reconstructed 2D array (enhanced_image)\n",
    "    '''\n",
    "    image = image_array[0]\n",
    "    image = img_as_float(image)\n",
    "    image_blurred = gaussian_filter(image, 1)\n",
    "    seed = np.copy(image)\n",
    "    seed[1:-1, 1:-1] = image.min()\n",
    "    mask = image\n",
    "    dilated = reconstruction(seed, mask, method='dilation')\n",
    "    enhanced_image = image - dilated\n",
    "    return enhanced_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_threshold(channel_data_array, percentile):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (channel_data_array); a percentage value (percentile)\n",
    "    This function:\n",
    "        Calculates the threshold value.   \n",
    "    This function returns:\n",
    "        A threshold value (threshold_value)\n",
    "    '''\n",
    "    top_percentile_value = 100 - percentile\n",
    "    threshold_value = np.percentile(channel_data_array[0], top_percentile_value)\n",
    "    return threshold_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image_array):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array); a percentage value (percentile)\n",
    "    This function:\n",
    "        Performs a variety of morphological operations, speciifcally\n",
    "        closing, dilation, skeletonization, dilation, and skeletonization    \n",
    "    This function returns:\n",
    "        A 2D array that has been morphed (final_image)\n",
    "    '''\n",
    "    \n",
    "    opened_image = morphology.closing(image_array, morphology.square(3))\n",
    "    # plt.imshow(opened_image)\n",
    "    dilated = morphology.dilation(opened_image, morphology.rectangle(50,1))\n",
    "    # plt.imshow(~dilated)\n",
    "    skel = morphology.medial_axis(opened_image, return_distance= False)\n",
    "    # plt.imshow(skel)\n",
    "    skeltized = morphology.skeletonize(dilated)\n",
    "    # plt.imshow(skeltized)\n",
    "\n",
    "    dilated2 = morphology.dilation(skeltized,morphology.rectangle(50,1))\n",
    "    skeltized2 = morphology.skeletonize(dilated2)\n",
    "    \n",
    "    # cleaned = remove_small_objects(skeltized2, min_size = 2)\n",
    "\n",
    "    final_image = opened_image\n",
    "    return final_image #Returns final result of skeletized\n",
    "\n",
    "    ##Notes: Vertically long rectangles do best, The more horizontal it is the more it will grow horizontally and connect\n",
    "    ##A Square kernel initially is best to dilate and erode without losing too much. Using other shapes causises issues\n",
    "    ## \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "plt.figure()\n",
    "print(array)\n",
    "removed = remove_noise(array)\n",
    "original_image = tf.imread('data/channels_directory/channel_1.tiff')\n",
    "overlay = (~original_image) * (~removed)\n",
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section is the testing area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local Maximums USE SKIPY Percentages\n",
    "\n",
    "## THIS CONVERTS TO FLOAT 64\n",
    "\n",
    "def find_local_maximums(image_array):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array)\n",
    "    This function:\n",
    "        Loops through each row of the original image and uses the find_peaks() method\n",
    "        in order to find the local peaks of the row.\n",
    "    This function returns:\n",
    "        A 2D array with 0s and the peak values at the \n",
    "        corresponding index location of the original image\n",
    "    Note: the find_peaks() function will return a int64 array.\n",
    "    '''\n",
    "    rows = len(image_array) \n",
    "    cols = len(image_array[0])\n",
    "    peaks_indices_array = []\n",
    "    new_image_array = np.zeros((rows, cols), dtype=np.uint16)\n",
    "    for row in range(len(image_array) - 1):\n",
    "        peaks, properties = find_peaks(image_array[row], height=(1500,23000), threshold=None, distance=3, \n",
    "                                          prominence=None, width=50, wlen=None, rel_height=100, \n",
    "                                          plateau_size=None)\n",
    "        prom_array = peak_prominences(image_array[row], peaks)\n",
    "        peaks_indices_array.append(peaks)\n",
    "    for i in range(len(image_array) - 1):\n",
    "        for j in range(len(image_array[i]) - 1):\n",
    "            if (j in peaks_indices_array[i]):\n",
    "                new_image_array[i][j] = image_array[i][j]\n",
    "    return new_image_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This shows the original cropped image\n",
    "im = plt.imread(\"data/cropped_images/cropped_image_channel_1.tiff\")\n",
    "plt.figure()\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section finds the local maximums of the image\n",
    "plt.figure()\n",
    "# print(im.dtype)\n",
    "test_array = find_local_maximums(im) \n",
    "plt.imshow(test_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_change(final, original_value):\n",
    "    '''\n",
    "    This function calculates the percentage threshold. If the two values are within the threshold then a boolean True will\n",
    "    be returned. Otherwise a boolean False will be returned.\n",
    "    '''\n",
    "    percentage_threshold = 50\n",
    "    calculated_percent = ((final - original_value) / original_value) * 100.0\n",
    "    if calculated_percent > percentage_threshold and calculated_percent >= 0:\n",
    "        # print(\"true\")\n",
    "        return True\n",
    "    else:\n",
    "        # print(\"false\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##construct small array \n",
    "def split_array(array, pixel_location, max_distance_from_pixel_loc):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (array); a pixel location [pixel_location], and a maximum distance from the\n",
    "        pixel location (max_distance_from_pixel_loc)\n",
    "    This function:\n",
    "        Splits the array at the pixel location into a left and right array.\n",
    "    This function returns:\n",
    "        An array of arrays, where the sub-arrays are the left and right side arrays from the pixel \n",
    "        location\n",
    "    '''\n",
    "    right_array = []\n",
    "    left_array = []\n",
    "    left_and_right = []\n",
    "    # If the pixel's locations left side is negative, indicating it is on the far left\n",
    "    if pixel_location - max_distance_from_pixel_loc < 0: \n",
    "        # Determines if it is on the edge of the image\n",
    "        if pixel_location - max_distance_from_pixel_loc == -1 * max_distance_from_pixel_loc:\n",
    "            left_array = []\n",
    "        else:\n",
    "            left_array = array[0 : pixel_location]\n",
    "        right_array = array[pixel_location: pixel_location + max_distance_from_pixel_loc]\n",
    "    # If the pixel's location right side is greater than the row length\n",
    "    elif (pixel_location + max_distance_from_pixel_loc) > (len(array) - 1):\n",
    "        right_array = []\n",
    "        left_array = array[pixel_location - max_distance_from_pixel_loc: pixel_location-1]\n",
    "    # If the pixel location is the middle of the image\n",
    "    else: \n",
    "        left_array = array[pixel_location - max_distance_from_pixel_loc: pixel_location]\n",
    "        right_array = array[pixel_location + 1 : pixel_location + 1 + max_distance_from_pixel_loc]\n",
    "    # Appends the arrays to a final array which is returned\n",
    "    left_and_right.append(left_array)\n",
    "    left_and_right.append(right_array)\n",
    "    return left_and_right\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithm(new_image_array, b, pixel_tolerance ):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (new_image_array); a background value (b), and a pixel tolerance (pixel_tolerance)\n",
    "    This function:\n",
    "        This loops through the image and determines the percentage change of the left and right side array of the corresponding\n",
    "        pixel. It then determines if this pixel should be changed or set to 0. This function aims to make continous axon\n",
    "        fragment lines\n",
    "    This function returns:\n",
    "        A 2D array which is process array.\n",
    "    '''\n",
    "   \n",
    "    n = pixel_tolerance #pixels away no longer count maximum values\n",
    "    mean_of_background = b\n",
    "    non_empty_row = 0\n",
    "\n",
    "    for i in range(len(new_image_array) - 1): ## Loops through the rows\n",
    "        # print(f\"row mean: {np.mean(new_image_array[i])}\")\n",
    "        if np.mean(new_image_array[i]) > mean_of_background: ## This is how I determine if a row is important (contains potential axons)\n",
    "            # print(\"passed mean test\")\n",
    "            non_empty_row +=1 ## Increments the row count\n",
    "\n",
    "            if non_empty_row != 1 : ## want to leave first row untouched, just want to load it                \n",
    "                for j in range(len(new_image_array[i] - 1)): ## Loops through the columns\n",
    "                    splitted_array = split_array(new_image_array[i-1], j, n) ## Checks the row above and splits the array into the left and right\n",
    "                    combined_val = 0 # Value to calculate the combined value\n",
    "                    left_side_boolean = False\n",
    "                    right_side_boolean = False\n",
    "                    for k in range(len(splitted_array)): # Loops through the array (size of 2)\n",
    "                        if percentage_change(new_image_array[i][j], np.mean(splitted_array[k])) == True: ## If the pixel value at the specific pixel location meets the minimum threshold change \n",
    "                            combined_val += np.mean(splitted_array[k]) # Updates combined value\n",
    "                            if k == 0:\n",
    "                                left_side_boolean = True\n",
    "                            if k == 1:\n",
    "                                right_side_boolean = True\n",
    "                        if k == 1:\n",
    "\n",
    "                            if left_side_boolean == True and right_side_boolean == True :\n",
    "                                new_image_array[i][j] = combined_val # Sets the original array value\n",
    "                                combined_val = 0\n",
    "                            elif((left_side_boolean == False and right_side_boolean == True) or\n",
    "                                         (left_side_boolean == True and right_side_boolean == False)):\n",
    "                                new_image_array[i][j] = 0 # Sets the original array value\n",
    "                                combined_val = 0\n",
    "        else:\n",
    "            # print(\"failed mean test\")\n",
    "            non_empty_row = 0 ## Resets it to the \n",
    "    return new_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "print(test_array.dtype)\n",
    "output_array = test_algorithm(test_array,500, 10 )\n",
    "print(output_array.dtype)\n",
    "\n",
    "# final = output_array * test_array\n",
    "# plt.imshow(output_array)\n",
    "# print(output_array.shape)\n",
    "\n",
    "\n",
    "final = test_algorithm(remove_noise(output_array * test_array),9.9**7, 10 )\n",
    "plt.imshow(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_lines(lines, distance_threshold):\n",
    "    lines = np.squeeze(lines)\n",
    "    lines = lines.tolist()\n",
    "\n",
    "    # print (f\"lines after tolist() :{lines}\")\n",
    "    # Helper function to check if the distance between two points is within the threshold\n",
    "    \n",
    "    def is_within_distance(p1, p2, threshold):\n",
    "        distance = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "        return distance <= threshold\n",
    "\n",
    "\n",
    "    # Helper function to merge two lines into one\n",
    "    def merge_two_lines(line1, line2):\n",
    "        return [line1[0], line1[1], line2[2], line2[3]]\n",
    "    \n",
    "    def possible_merges(array,distance_threshold):\n",
    "        for i in range (len(array)-1):\n",
    "            x1,y1,x2,y2 = array[i] ## line one\n",
    "            for j in range(i + 1, len(array)):  # Start from i + 1 to avoid redundant checks\n",
    "                    x3,y3,x4,y4 =array[j]\n",
    "                    if is_within_distance((x2, y2), (x3, y3), distance_threshold) or \\\n",
    "                    is_within_distance((x1, y1), (x4, y4), distance_threshold):\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    while possible_merges(lines, distance_threshold): ## while there are still possible merges\n",
    "        print(len(lines))\n",
    "        for i in range(len(lines)):\n",
    "            x1, y1, x2, y2 = lines[i] ## gets line 1 \n",
    "            for j in range (len(lines)):\n",
    "                merged = False\n",
    "                if j != i:\n",
    "                    x3, y3, x4, y4 = lines[j] ## gets line 2\n",
    "                    if is_within_distance((x2, y2), (x3, y3), distance_threshold) or \\\n",
    "                    is_within_distance((x1, y1), (x4, y4), distance_threshold) : ## end and start\n",
    "                        merged_line = merge_two_lines([x1, y1, x2, y2], [x4, y4, x3, y3]) ## merge the lines\n",
    "                        lines.pop(j)\n",
    "                        lines.pop(i)\n",
    "                        lines.append(merged_line)\n",
    "                        merged = True\n",
    "                        break\n",
    "            if merged:\n",
    "                print(\"merged\")\n",
    "                print(f\"i: {i}\")\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell below aims to detect axon fragments(continous lines) to then be able to measure them after this cell.\n",
    "##WIP: Currently not working, overexposing the image.\n",
    "def detect_lines (image_array):\n",
    "    \n",
    "    min_16bit = 0\n",
    "    max_16bit = (2**16)-1\n",
    "\n",
    "    min = 7.0 * (10**3)\n",
    "    max = 8.0 * (10**3)\n",
    "\n",
    "    normalized_min = ((min - min_16bit) / (max_16bit - min_16bit)) * 255\n",
    "    normalized_max = ((max - min_16bit) / (max_16bit - min_16bit)) * 255\n",
    "\n",
    "    normalized_image = cv.normalize(image_array, None, 0, 255, cv.NORM_MINMAX).astype(np.uint8)\n",
    "    # plt.imshow(final)\n",
    "    edges = cv.Canny(normalized_image, normalized_min, normalized_max)\n",
    "\n",
    "    # merged_lines = merge_lines(edges,15)  # Merge lines\n",
    "\n",
    "    cdst = cv.cvtColor(edges, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    # cdst = cv.cvtColor(edges, cv.COLOR_GRAY2BGR)\n",
    "    cdstP = np.copy(cdst)\n",
    "\n",
    "    # lines = cv.HoughLines(edges,1, np.pi / 180, 200)\n",
    "\n",
    "    linesP = cv.HoughLinesP(edges, 1, np.pi / 180, 50, None, 0, 15)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(linesP)\n",
    "    \n",
    "    if isinstance(linesP, np.ndarray):\n",
    "        print(\"linesP is a NumPy array.\")\n",
    "        print(f\"before merge_lines: {linesP}\")\n",
    "    else:\n",
    "        print(\"linesP is not a NumPy array.\")\n",
    "        \n",
    "    merged_lines = merge_lines(linesP, 15)  # Merge lines\n",
    "\n",
    "    def calculate_line_lengths(lines):\n",
    "        lengths = np.sqrt((lines[:, 2] - lines[:, 0])**2 + (lines[:, 3] - lines[:, 1])**2)\n",
    "        return lengths\n",
    "    \n",
    "    def analyze_line_lengths(lengths):\n",
    "        mean_length = np.mean(lengths)\n",
    "        median_length = np.median(lengths)\n",
    "        std_dev = np.std(lengths)\n",
    "        quantiles = np.percentile(lengths, [25, 50, 75])\n",
    "    \n",
    "        stats = {\n",
    "            'mean': mean_length,\n",
    "            'median': median_length,\n",
    "            'std_dev': std_dev,\n",
    "            'quantiles': quantiles\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    line_lengths = calculate_line_lengths(merged_lines)\n",
    "    print(f\"Line lengths: {line_lengths}\")\n",
    "\n",
    "    # Analyze lengths\n",
    "    stats = analyze_line_lengths(line_lengths)\n",
    "    print(f\"Mean length: {stats['mean']}\")\n",
    "    print(f\"Median length: {stats['median']}\")\n",
    "    print(f\"Standard deviation: {stats['std_dev']}\")\n",
    "    print(f\"Quantiles (25th, 50th, 75th): {stats['quantiles']}\")\n",
    "\n",
    "    # Count the number of lines\n",
    "    num_lines = len(merged_lines)\n",
    "    print(f\"Number of lines: {num_lines}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # cv.imshow(\"Source\", image_array)\n",
    "    # cv.imshow(\"Detected Lines (in red) - Standard Hough Line Transform\", cdst)\n",
    "    # cv.imshow(\"Detected Lines (in red) - Probabilistic Line Transform\", cdstP)\n",
    "    # print(f\"Number of lines detected: {line_count}\")\n",
    "    # print(f\"Lengths of detected lines: {line_lengths}\")\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow( image_array)\n",
    "    # plt.figure()\n",
    "    # plt.imshow( cdst)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cdstP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detect_lines(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch work for EDA of axon fragment imaging\n",
    "\n",
    "As part of Mayoral lab investigation of oligodendrocyte precursor cell influence on neurodegenertation, have fluroescent images with channels:\n",
    "- GFP (sparse axonal labeling)\n",
    "- DegenoTag\n",
    "- Myelin staining\n",
    "- DAPI\n",
    "\n",
    "Goal is to development automated pipelines for assessing degree of degeration across different samples. Initial goal is to develop algorithms for detecting and statistically characterizing fragments of axons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import block\n",
    "\n",
    "# System\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# CSV Handling\n",
    "import csv\n",
    "\n",
    "# Image handling\n",
    "import tifffile as tf \n",
    "import imageio as img # tiff writing\n",
    "import czifile\n",
    "from tifffile import imsave, imread, imwrite\n",
    "\n",
    "# Numerical and statistics\n",
    "import seaborn as sb\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "from scipy.stats import mode\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Image analysis\n",
    "import cv2 as cv\n",
    "import skimage as sk\n",
    "from skimage import io, morphology\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import data\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Parsing Cell\n",
    "## The purpose of the cell below is to\n",
    "- Read the CSV Files\n",
    "- Parse the CSV Files\n",
    "- Extract statistical information from the fragment lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of LH_1.csv:\n",
      "[84.624, 79.256, 68.763, 38.822, 33.79, 225.743, 187.315, 29.584, 45.653, 358.301, 231.174, 257.38, 146.254, 82.068, 69.208, 369.093, 245.201, 121.703, 125.837, 860.626, 203.783, 42.512, 115.779, 210.606, 321.926, 125.023, 143.462, 19.638, 43.184, 66.969, 54.852, 278.328, 115.111, 118.677, 24.842, 88.543, 29.0, 514.726, 94.274, 110.473, 185.345, 69.75, 100.387, 97.575, 18.458, 23.622, 11.04, 84.409, 97.608, 325.75, 25.877, 89.277, 160.668, 138.099, 203.579, 510.554, 102.338, 40.917, 164.256, 31.172, 133.408, 66.145, 33.562, 78.23, 9.289, 22.916, 45.386, 23.695, 21.835, 43.738, 69.091, 165.427, 860.626, 250.764, 322.664, 123.76, 454.004, 126.9, 86.944, 55.524, 288.349, 108.527, 302.21, 152.735, 121.446, 67.295, 68.474, 80.412, 97.344, 158.235, 116.296, 90.375, 103.575, 49.048, 198.611, 393.199, 118.675, 77.873, 265.574, 562.371, 677.091]\n",
      "\n",
      "\n",
      "Contents of S_1.csv:\n",
      "[256.435, 81.9, 74.81, 58.653, 221.698, 872.517, 144.207, 122.051, 140.213, 56.711, 596.057, 390.922, 207.845, 110.343, 29.241, 377.201, 53.203, 86.116, 509.768, 312.2, 84.682, 43.246, 160.921, 86.352, 183.486, 172.242, 153.357, 33.697, 218.603, 243.361, 323.444, 30.707, 326.64, 51.461, 69.131, 90.864, 74.317, 240.812, 117.882, 69.483, 29.567, 154.739, 144.944, 124.479, 44.76, 57.203, 212.209, 41.903, 70.864, 159.243, 332.996, 115.829, 81.935, 49.696, 115.325, 55.872, 41.378, 48.555]\n",
      "\n",
      "\n",
      "Contents of SM_1.csv:\n",
      "[74.071, 57.27, 10.029, 82.689, 40.856, 207.093, 16.029, 7.714, 20.803, 122.295, 184.548, 16.617, 36.433, 29.702, 119.488, 26.22, 23.133, 22.937, 8.535, 21.655, 40.733, 54.527, 106.341, 47.869, 355.202, 226.509, 30.086, 10.594, 262.558, 261.311, 113.322, 297.45, 44.252, 96.959, 14.49, 123.931, 551.784, 173.051, 81.794, 81.992, 136.961, 63.054, 152.688, 107.211, 103.715, 265.908, 31.205, 218.728, 111.857, 20.096, 143.925, 73.643, 564.498, 32.437, 109.238, 122.55, 221.591, 319.522, 100.229, 155.529, 694.301, 15.525, 79.373, 91.228, 57.075, 316.746, 144.813, 48.162, 445.486, 93.011, 20.117, 5.563, 87.109, 45.519, 60.099, 41.185, 13.272, 41.333, 93.592, 65.063, 107.075, 25.244, 16.56, 18.681, 64.293, 27.154, 114.36, 21.39, 7.59, 266.796, 82.164, 113.994, 81.854, 98.365, 207.16, 65.434, 53.601, 120.078, 39.344, 48.013, 23.351, 55.011, 96.649, 115.436, 13.817, 144.259, 66.491, 49.723, 78.925, 60.736, 30.391, 320.966, 124.927, 50.067, 68.435, 52.795, 112.934, 57.738, 79.802, 61.529, 19.989, 46.701, 50.757, 75.725, 17.867, 49.04, 22.911, 19.692, 60.173, 22.77, 39.452]\n",
      "\n",
      "\n",
      "Contents of GM_1.csv:\n",
      "[82.375, 77.493, 69.132, 182.915, 191.157, 141.117, 31.652, 212.364, 37.656, 556.558, 290.802, 31.43, 94.05, 19.062, 121.004, 156.828, 90.774, 16.521, 227.555, 1.422, 3.181, 140.295, 68.227, 112.071, 69.486, 322.091, 31.838, 432.621, 79.133, 123.735, 128.697, 56.121, 88.516, 78.046, 56.824, 67.601, 24.199, 38.862, 115.056, 18.66, 12.758, 35.944, 48.965, 84.105, 117.643, 90.432, 318.153, 140.609, 59.393, 94.023, 44.473, 69.556, 67.765, 344.422, 177.857, 24.149, 76.223, 8.712, 2.182, 211.358, 128.669, 457.244, 237.328, 104.201, 124.438, 167.993, 261.739, 147.336, 110.295, 32.58, 14.616, 66.169, 139.481, 109.429, 48.349, 92.009, 149.94, 22.294, 128.253, 260.928, 207.087, 106.578]\n",
      "\n",
      "\n",
      "Contents of CS_1.csv:\n",
      "[70.112, 83.027, 39.121, 84.459, 79.879, 462.457, 1250.996, 434.302, 118.294, 52.314, 125.28, 540.104, 306.266, 271.116, 61.739, 248.217, 183.012, 143.553, 196.279, 106.037, 58.927, 46.649, 48.614, 81.531, 72.719, 90.219, 58.266, 26.431, 257.833, 142.899, 78.498, 61.123, 127.926, 81.611, 63.275, 103.477, 33.257, 111.928, 150.509, 128.493, 292.11, 131.919, 162.41, 25.54, 194.357, 296.023, 447.124, 212.999, 119.91, 264.362, 119.186, 398.345, 1009.105, 52.716, 791.011, 250.289, 297.86, 374.05, 128.763, 236.596, 275.756, 183.179, 138.295, 164.907, 168.151]\n",
      "\n",
      "\n",
      "Contents of MM_1.csv:\n",
      "[11.232, 12.591, 8.309, 71.057, 151.806, 107.099, 28.955, 65.569, 6.104, 142.728, 93.526, 19.364, 57.318, 89.156, 41.546, 68.077, 62.423, 78.744, 51.306, 19.7, 44.444, 143.33, 69.009, 54.41, 124.736, 75.768, 128.066, 91.375, 74.85, 37.977, 46.925, 24.728, 111.371, 114.958, 515.586, 21.792, 90.892, 52.551, 44.815, 105.787, 116.424, 147.294, 85.587, 390.11, 112.853, 206.141, 65.061, 92.5, 227.357, 369.804, 58.878, 141.459, 56.44, 95.581, 40.205, 83.551, 59.172, 30.111, 86.633, 47.769, 29.755, 112.476, 9.66, 187.171, 86.115, 323.042, 198.682, 124.906, 319.91, 449.478, 118.812, 148.827, 16.108, 550.604, 95.148, 315.56, 303.814, 113.458, 236.539, 102.07, 68.393, 73.692, 315.811, 368.056, 203.504, 146.641, 868.859, 43.849, 36.696, 98.676, 240.762, 115.437, 105.737, 119.886, 37.492, 41.615, 206.31, 303.874, 220.056, 217.502, 178.863, 345.433, 31.475, 276.144, 80.633, 38.76, 66.458, 74.148, 37.63, 103.287, 41.815, 96.997, 157.654, 205.845]\n",
      "\n",
      "\n",
      "Contents of IHR_1.csv:\n",
      "[39.966, 38.107, 83.573, 213.35, 17.567, 225.487, 71.205, 79.169, 33.867, 370.384, 298.085, 98.68, 564.877, 245.24, 148.784, 20.07, 126.009, 205.111, 295.4, 73.457, 459.546, 198.716, 64.114, 111.525, 91.4, 90.475, 33.096, 129.126, 247.02, 105.802, 164.588, 128.013, 44.786, 54.135, 84.729, 60.349, 80.468, 59.492, 10.348, 80.799, 88.193, 218.999, 160.305, 91.914, 77.254, 39.494, 58.802, 59.937, 46.717, 96.769, 73.804, 20.598, 43.548, 42.848, 14.51, 200.425, 78.411, 121.031, 91.606, 87.195, 18.871, 19.414, 69.86, 31.79, 130.264, 102.841, 217.151, 70.711, 23.232, 245.952, 86.448, 100.827, 83.276, 31.5, 94.627, 58.2, 25.048, 58.822, 37.336, 64.167, 25.684, 16.453, 87.547, 48.469, 15.969, 83.42, 19.002, 140.485, 40.895, 47.075, 26.116, 32.416, 52.654, 24.6, 16.317, 45.144, 110.647, 109.984, 118.031, 58.463, 51.642, 40.801, 117.767, 24.97, 19.284, 13.011, 14.394, 90.816, 30.38, 53.494, 45.518, 50.701, 74.076, 16.739, 71.205, 115.593, 56.503, 42.316, 39.307, 51.768, 81.655, 89.573, 79.757, 40.718, 46.181, 72.351, 28.219, 35.86, 114.512, 56.587, 29.185, 17.798, 46.094, 109.893, 49.079, 23.651, 28.061, 22.413, 10.911, 22.454, 47.953, 48.399, 60.803, 36.746, 215.389, 48.152, 65.514, 78.637, 66.329, 27.811, 31.532, 68.734, 105.08, 35.016, 30.92, 10.418, 42.171, 52.71, 46.617, 30.94, 28.742, 52.922, 34.635, 23.101, 102.975, 28.831, 65.768, 289.855, 12.513, 176.928, 124.056, 137.34, 83.269, 26.273, 37.664, 61.147, 174.486, 13.8, 17.005, 17.738, 226.759, 167.719, 105.958, 60.209, 41.42, 25.277, 39.101, 89.804, 13.591, 11.139, 27.307, 23.411, 55.15, 83.106, 65.279, 71.018, 19.887, 24.083, 48.036, 53.2, 65.456, 60.242, 50.313, 41.773, 28.966, 62.029, 37.124, 60.282, 26.532, 47.761, 69.529, 33.702, 13.722, 46.446, 9.855, 47.598, 71.039, 29.584, 30.146, 11.292, 28.694, 11.111, 18.03, 23.849, 20.706, 19.376, 9.735, 7.693, 8.368, 22.944, 30.921, 35.318]\n",
      "\n",
      "\n",
      "Contents of E_1.csv:\n",
      "[77.223, 181.077, 23.637, 126.111, 145.433, 106.498, 39.022, 73.974, 28.24, 93.816, 58.031, 70.883, 66.645, 42.56, 74.833, 74.833, 60.329, 86.393, 63.344, 63.344, 18.572, 28.617, 149.677, 259.1, 133.994, 65.599, 65.599, 151.269, 117.079, 64.301, 137.973, 31.224, 31.224, 139.483, 261.625, 142.29, 74.867, 529.212, 36.325, 406.023, 124.145, 225.198, 245.457, 245.793, 60.917, 390.772, 126.786, 93.643, 49.897, 32.363, 184.141, 81.759, 341.71, 46.66, 324.94, 201.05, 54.34, 75.192, 108.304, 250.922, 160.494, 63.928, 34.835, 203.087, 340.519, 222.15, 263.556, 155.017, 110.025, 97.453, 154.147, 178.996, 271.7, 352.987, 352.987, 118.198, 570.341, 133.24, 97.784, 164.42, 244.728, 178.016, 143.898, 150.667, 87.465, 256.814, 124.216, 295.08, 48.899, 41.4, 259.126, 290.166, 223.657, 356.01, 177.196, 72.502, 77.571, 32.34, 209.962, 40.946, 40.667, 82.206, 31.551, 27.945, 51.287, 48.51, 62.429, 169.853, 99.758, 32.21, 147.803]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "roi_directory = 'data/ROI'\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(roi_directory) if f.endswith('.csv')]\n",
    "# Loop through each CSV file and read its contents\n",
    "total_lengths_array = []\n",
    "for csv_file in csv_files:\n",
    "  csv_lengths_array = []\n",
    "  file_path = os.path.join(roi_directory, csv_file)\n",
    "  with open(file_path, 'r') as file:\n",
    "      csvreader = csv.reader(file)\n",
    "      print(f\"Contents of {csv_file}:\")\n",
    "      header = next(csvreader)\n",
    "      for row in csvreader:\n",
    "        csv_lengths_array.append(row[5])\n",
    "      # print(row[5])\n",
    "      # print(csv_lengths_array)\n",
    "      numeric_values = [float(num) for num in csv_lengths_array]\n",
    "      print(numeric_values)\n",
    "      total_lengths_array.append(numeric_values)\n",
    "  print(\"\\n\")  # Add a newline for better readability between files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual sub-array means: [157.96442574257426, 161.3495862068966, 101.4063969465649, 119.91225609756096, 206.39556923076924, 132.3073245614035, 73.12383189655172, 142.47756756756755]\n",
      "Overall mean: 122.71612080536913\n",
      "Standard deviation: 131.62299580634402\n",
      "Median: 81.707\n",
      "Quantiles (25th, 50th, 75th): [ 42.632    81.707   147.13075]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_sum = 0\n",
    "respective_sub_means = []\n",
    "for i in range(len(total_lengths_array)):\n",
    "    respective_sub_means.append(np.mean(total_lengths_array[i]))\n",
    "    \n",
    "\n",
    "# Flatten the list of arrays and calculate statistics\n",
    "all_lengths = np.concatenate([np.array(arr) for arr in total_lengths_array])\n",
    "\n",
    "# Mean, standard deviation, median, quantiles\n",
    "mean_all = np.mean(all_lengths)\n",
    "std_dev = np.std(all_lengths)\n",
    "median_all = np.median(all_lengths)\n",
    "quantiles = np.percentile(all_lengths, [25, 50, 75])\n",
    "print(f\"Individual sub-array means: {respective_sub_means}\")\n",
    "print(f\"Overall mean: {mean_all}\")\n",
    "print(f\"Standard deviation: {std_dev}\")\n",
    "print(f\"Median: {median_all}\")\n",
    "print(f\"Quantiles (25th, 50th, 75th): {quantiles}\")\n",
    "## find standard deviation, median, quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets the view mode of matplotlib\n",
    "if 1:\n",
    "    %matplotlib qt\n",
    "    plt.ion()\n",
    "else:\n",
    "    %matplotlib inline\n",
    "    plt.ion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing stage\n",
    " This section will do the following:\n",
    " - Convert CZI files to TIFF\n",
    " - Read the images into respective image arrays\n",
    " - Crop the image arrays to the respective region of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: CTRL_INT_4.czi to data/tiff_images_directory \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/xjfqff1j40q09wj54wk3p2w80000gn/T/ipykernel_5525/1193108092.py:26: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tf.imsave(output_file_path, image_array, imagej=True)\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "This cell takes in a particular input directory and output directory to convert the czi files to tiff files.\n",
    "'''\n",
    "\n",
    "main_directory = \"data\"\n",
    "input_directory = os.path.join(main_directory, \"czi_images_directory\")\n",
    "output_directory = os.path.join(main_directory, \"tiff_images_directory\")\n",
    "\n",
    "# Check if output directory exists, create if not\n",
    "if not os.path.exists(output_directory):\n",
    "    print(\"Output Directory not found, creating one \\n\")\n",
    "    os.makedirs(output_directory)\n",
    "    print(\"Output Directory successfully created \\n\")\n",
    "\n",
    "# Loop through files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    full_file_path = os.path.join(input_directory, filename)\n",
    "    \n",
    "    # Check if it is a file and has a .czi extension\n",
    "    if os.path.isfile(full_file_path) and filename.lower().endswith('.czi'):\n",
    "        with czifile.CziFile(full_file_path) as czi:\n",
    "            image_array = czi.asarray()\n",
    "        \n",
    "        # Save the image as TIFF in the output directory\n",
    "        output_file_path = os.path.join(output_directory, filename + '.tiff')\n",
    "        tf.imsave(output_file_path, image_array, imagej=True)\n",
    "        print(f\"Successfully converted: {filename} to {output_directory} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(channel_array):  \n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (channel_array which is ideally a channel of an array) \n",
    "        \n",
    "    This function:\n",
    "        Crops of the image to the specified x and y limits \n",
    "\n",
    "    This function returns:\n",
    "        a cropped 2D array\n",
    "    '''\n",
    "    x_min = 2200\n",
    "    x_max = 3200\n",
    "    y_min = 1100\n",
    "    y_max = 3000\n",
    "    return channel_array[y_min:y_max, x_min:x_max]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This array stores the information of the 2D arrays of the channel for statistical analysis\n",
    "channel_data_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_before_crop(image_array):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array) \n",
    "        \n",
    "    This function:\n",
    "        Flattens the 2D array and sorts it numerically\n",
    "\n",
    "    This function returns:\n",
    "        The flattened and sorted 1D array (sorted_pixel_values)\n",
    "    '''\n",
    "    pixel_values = image_array.flatten()\n",
    "    sorted_pixel_values = np.sort(pixel_values)\n",
    "    return sorted_pixel_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_channels(tiff_image):\n",
    "    ''' \n",
    "    This function takes in:\n",
    "        A image path to a tiff image (tiff_image)\n",
    "        \n",
    "    This function:\n",
    "        Reads the image, splits the image into its distinct channels and adds those arrays to an array of arrays.\n",
    "\n",
    "    This function returns:\n",
    "        An array of arrays (image_channel_arrays)\n",
    "        \n",
    "    ''' \n",
    "    image_array = tf.imread(tiff_image) #Gets the image array\n",
    "    image_channels_array = []\n",
    "    num_channels = image_array.shape[0] # Gets the number of channels\n",
    "    for channel in range(num_channels):\n",
    "        channel_data = image_array[channel]  # Extract data for one channel\n",
    "        channel_data_array.append(save_array_before_crop(channel_data))\n",
    "        image_channels_array.append(channel_data)\n",
    "    return image_channels_array\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved cropped channel 1 to data/cropped_images/cropped_image_channel_1.tiff \n",
      "\n",
      "Successfully saved cropped channel 2 to data/cropped_images/cropped_image_channel_2.tiff \n",
      "\n",
      "Successfully saved cropped channel 3 to data/cropped_images/cropped_image_channel_3.tiff \n",
      "\n",
      "Successfully saved cropped channel 4 to data/cropped_images/cropped_image_channel_4.tiff \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/xjfqff1j40q09wj54wk3p2w80000gn/T/ipykernel_5525/3388603868.py:13: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tf.imsave(output_file_path, cropped_channel, imagej=True)\n"
     ]
    }
   ],
   "source": [
    "# This runs the command to splits the channels and saves them into the channels_directory\n",
    "array = split_channels('data/tiff_images_directory/CTRL_INT_4.czi.tiff')\n",
    "\n",
    "# Loop through the channels and save each one\n",
    "for i, channel in enumerate(array):\n",
    "    # Save the image using tifffile\n",
    "    tf.imwrite(os.path.join(\"data/channels_directory\", f'channel_{i+1}.tiff'), channel)\n",
    "\n",
    "## crops and saves the images to the directory\n",
    "cropped_array = [crop_image(channel) for channel in array]\n",
    "for j, cropped_channel in enumerate(cropped_array):\n",
    "    output_file_path = os.path.join(\"data/cropped_images\", \"cropped_image_channel_\" + str(j + 1) + \".tiff\")\n",
    "    tf.imsave(output_file_path, cropped_channel, imagej=True)\n",
    "    print(f\"Successfully saved cropped channel {j + 1} to {output_file_path} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin anaylsis\n",
    "\n",
    "In this code segment we will be doing the following:\n",
    "- Defining the threshhold of for the image\n",
    "- Reconstructing the image (WIP)\n",
    "- Removing noise and skeletizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_of_image(image_array): \n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array)\n",
    "    This function:\n",
    "        Performs a morphological reconstruction of the 2D array\n",
    "    This function returns:\n",
    "        A reconstructed 2D array (enhanced_image)\n",
    "    '''\n",
    "    image = image_array[0]\n",
    "    image = img_as_float(image)\n",
    "    image_blurred = gaussian_filter(image, 1)\n",
    "    seed = np.copy(image)\n",
    "    seed[1:-1, 1:-1] = image.min()\n",
    "    mask = image\n",
    "    dilated = reconstruction(seed, mask, method='dilation')\n",
    "    enhanced_image = image - dilated\n",
    "    return enhanced_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_threshold(channel_data_array, percentile):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (channel_data_array); a percentage value (percentile)\n",
    "    This function:\n",
    "        Calculates the threshold value.   \n",
    "    This function returns:\n",
    "        A threshold value (threshold_value)\n",
    "    '''\n",
    "    top_percentile_value = 100 - percentile\n",
    "    threshold_value = np.percentile(channel_data_array[0], top_percentile_value)\n",
    "    return threshold_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image_array):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array); a percentage value (percentile)\n",
    "    This function:\n",
    "        Performs a variety of morphological operations, speciifcally\n",
    "        closing, dilation, skeletonization, dilation, and skeletonization    \n",
    "    This function returns:\n",
    "        A 2D array that has been morphed (final_image)\n",
    "    '''\n",
    "    \n",
    "    opened_image = morphology.closing(image_array, morphology.square(3))\n",
    "    # plt.imshow(opened_image)\n",
    "    dilated = morphology.dilation(opened_image, morphology.rectangle(50,1))\n",
    "    # plt.imshow(~dilated)\n",
    "    skel = morphology.medial_axis(opened_image, return_distance= False)\n",
    "    # plt.imshow(skel)\n",
    "    skeltized = morphology.skeletonize(dilated)\n",
    "    # plt.imshow(skeltized)\n",
    "\n",
    "    dilated2 = morphology.dilation(skeltized,morphology.rectangle(50,1))\n",
    "    skeltized2 = morphology.skeletonize(dilated2)\n",
    "    \n",
    "    # cleaned = remove_small_objects(skeltized2, min_size = 2)\n",
    "\n",
    "    final_image = opened_image\n",
    "    return final_image #Returns final result of skeletized\n",
    "\n",
    "    ##Notes: Vertically long rectangles do best, The more horizontal it is the more it will grow horizontally and connect\n",
    "    ##A Square kernel initially is best to dilate and erode without losing too much. Using other shapes causises issues\n",
    "    ## \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  0,   0,   0, ..., 354, 354, 354],\n",
      "       [  0,   0,   0, ..., 354, 354, 354],\n",
      "       [  0,   0,   0, ..., 354, 354, 354],\n",
      "       ...,\n",
      "       [379, 379, 379, ...,   0,   0,   0],\n",
      "       [379, 379, 379, ...,   0,   0,   0],\n",
      "       [379, 379, 379, ...,   0,   0,   0]], dtype=uint16), array([[  0,   0,   0, ..., 430, 430, 430],\n",
      "       [  0,   0,   0, ..., 430, 430, 430],\n",
      "       [  0,   0,   0, ..., 430, 430, 430],\n",
      "       ...,\n",
      "       [492, 492, 492, ...,   0,   0,   0],\n",
      "       [492, 492, 492, ...,   0,   0,   0],\n",
      "       [492, 492, 492, ...,   0,   0,   0]], dtype=uint16), array([[ 0,  0,  0, ..., 91, 91, 91],\n",
      "       [ 0,  0,  0, ..., 91, 91, 91],\n",
      "       [ 0,  0,  0, ..., 91, 91, 91],\n",
      "       ...,\n",
      "       [93, 93, 93, ...,  0,  0,  0],\n",
      "       [93, 93, 93, ...,  0,  0,  0],\n",
      "       [93, 93, 93, ...,  0,  0,  0]], dtype=uint16), array([[  0,   0,   0, ..., 130, 130, 130],\n",
      "       [  0,   0,   0, ..., 130, 130, 130],\n",
      "       [  0,   0,   0, ..., 130, 130, 130],\n",
      "       ...,\n",
      "       [127, 127, 127, ...,   0,   0,   0],\n",
      "       [127, 127, 127, ...,   0,   0,   0],\n",
      "       [127, 127, 127, ...,   0,   0,   0]], dtype=uint16)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(array)\n\u001b[0;32m----> 4\u001b[0m removed \u001b[39m=\u001b[39m remove_noise(array)\n\u001b[1;32m      5\u001b[0m original_image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mdata/channels_directory/channel_1.tiff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m overlay \u001b[39m=\u001b[39m (\u001b[39m~\u001b[39moriginal_image) \u001b[39m*\u001b[39m (\u001b[39m~\u001b[39mremoved)\n",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36mremove_noise\u001b[0;34m(image_array)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremove_noise\u001b[39m(image_array):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    This function takes in:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m        A 2D array (image_array); a percentage value (percentile)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m        A 2D array that has been morphed (final_image)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     opened_image \u001b[39m=\u001b[39m morphology\u001b[39m.\u001b[39mclosing(image_array, morphology\u001b[39m.\u001b[39msquare(\u001b[39m3\u001b[39m))\n\u001b[1;32m     13\u001b[0m     \u001b[39m# plt.imshow(opened_image)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     dilated \u001b[39m=\u001b[39m morphology\u001b[39m.\u001b[39mdilation(opened_image, morphology\u001b[39m.\u001b[39mrectangle(\u001b[39m50\u001b[39m,\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/carneysummer/lib/python3.12/site-packages/skimage/morphology/misc.py:46\u001b[0m, in \u001b[0;36mdefault_footprint.<locals>.func_out\u001b[0;34m(image, footprint, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m footprint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     footprint \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39mgenerate_binary_structure(image\u001b[39m.\u001b[39mndim, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m func(image, footprint\u001b[39m=\u001b[39mfootprint, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/carneysummer/lib/python3.12/site-packages/skimage/morphology/gray.py:515\u001b[0m, in \u001b[0;36mclosing\u001b[0;34m(image, footprint, out, mode, cval)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return grayscale morphological closing of an image.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[39mThe morphological closing of an image is defined as a dilation followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m \n\u001b[1;32m    513\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    514\u001b[0m footprint \u001b[39m=\u001b[39m pad_footprint(footprint, pad_end\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 515\u001b[0m dilated \u001b[39m=\u001b[39m dilation(image, footprint, mode\u001b[39m=\u001b[39mmode, cval\u001b[39m=\u001b[39mcval)\n\u001b[1;32m    516\u001b[0m out \u001b[39m=\u001b[39m erosion(dilated, mirror_footprint(footprint), out\u001b[39m=\u001b[39mout, mode\u001b[39m=\u001b[39mmode, cval\u001b[39m=\u001b[39mcval)\n\u001b[1;32m    517\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/carneysummer/lib/python3.12/site-packages/skimage/morphology/misc.py:46\u001b[0m, in \u001b[0;36mdefault_footprint.<locals>.func_out\u001b[0;34m(image, footprint, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m footprint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     footprint \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39mgenerate_binary_structure(image\u001b[39m.\u001b[39mndim, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m func(image, footprint\u001b[39m=\u001b[39mfootprint, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/carneysummer/lib/python3.12/site-packages/skimage/morphology/gray.py:345\u001b[0m, in \u001b[0;36mdilation\u001b[0;34m(image, footprint, out, shift_x, shift_y, mode, cval)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    344\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 345\u001b[0m mode, cval \u001b[39m=\u001b[39m _min_max_to_constant_mode(image\u001b[39m.\u001b[39mdtype, mode, cval)\n\u001b[1;32m    347\u001b[0m footprint \u001b[39m=\u001b[39m _shift_footprints(footprint, shift_x, shift_y)\n\u001b[1;32m    348\u001b[0m footprint \u001b[39m=\u001b[39m pad_footprint(footprint, pad_end\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "# View\n",
    "plt.figure()\n",
    "print(array)\n",
    "removed = remove_noise(array)\n",
    "original_image = tf.imread('data/channels_directory/channel_1.tiff')\n",
    "overlay = (~original_image) * (~removed)\n",
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section is the testing area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local Maximums USE SKIPY Percentages\n",
    "\n",
    "## THIS CONVERTS TO FLOAT 64\n",
    "\n",
    "def find_local_maximums(image_array):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (image_array)\n",
    "    This function:\n",
    "        Loops through each row of the original image and uses the find_peaks() method\n",
    "        in order to find the local peaks of the row.\n",
    "    This function returns:\n",
    "        A 2D array with 0s and the peak values at the \n",
    "        corresponding index location of the original image\n",
    "    Note: the find_peaks() function will return a int64 array.\n",
    "    '''\n",
    "    rows = len(image_array) \n",
    "    cols = len(image_array[0])\n",
    "    peaks_indices_array = []\n",
    "    new_image_array = np.zeros((rows, cols), dtype=np.uint16)\n",
    "    for row in range(len(image_array) - 1):\n",
    "        peaks, properties = find_peaks(image_array[row], height=(1500,23000), threshold=None, distance=3, \n",
    "                                          prominence=None, width=50, wlen=None, rel_height=100, \n",
    "                                          plateau_size=None)\n",
    "        prom_array = peak_prominences(image_array[row], peaks)\n",
    "        peaks_indices_array.append(peaks)\n",
    "    for i in range(len(image_array) - 1):\n",
    "        for j in range(len(image_array[i]) - 1):\n",
    "            if (j in peaks_indices_array[i]):\n",
    "                new_image_array[i][j] = image_array[i][j]\n",
    "    return new_image_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17728ee10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This shows the original cropped image\n",
    "im = plt.imread(\"data/cropped_images/cropped_image_channel_1.tiff\")\n",
    "plt.figure()\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x286e9e3f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This section finds the local maximums of the image\n",
    "plt.figure()\n",
    "# print(im.dtype)\n",
    "test_array = find_local_maximums(im) \n",
    "plt.imshow(test_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_change(final, original_value):\n",
    "    '''\n",
    "    This function calculates the percentage threshold. If the two values are within the threshold then a boolean True will\n",
    "    be returned. Otherwise a boolean False will be returned.\n",
    "    '''\n",
    "    percentage_threshold = 50\n",
    "    calculated_percent = ((final - original_value) / original_value) * 100.0\n",
    "    if calculated_percent > percentage_threshold and calculated_percent >= 0:\n",
    "        # print(\"true\")\n",
    "        return True\n",
    "    else:\n",
    "        # print(\"false\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##construct small array \n",
    "def split_array(array, pixel_location, max_distance_from_pixel_loc):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (array); a pixel location [pixel_location], and a maximum distance from the\n",
    "        pixel location (max_distance_from_pixel_loc)\n",
    "    This function:\n",
    "        Splits the array at the pixel location into a left and right array.\n",
    "    This function returns:\n",
    "        An array of arrays, where the sub-arrays are the left and right side arrays from the pixel \n",
    "        location\n",
    "    '''\n",
    "    right_array = []\n",
    "    left_array = []\n",
    "    left_and_right = []\n",
    "    # If the pixel's locations left side is negative, indicating it is on the far left\n",
    "    if pixel_location - max_distance_from_pixel_loc < 0: \n",
    "        # Determines if it is on the edge of the image\n",
    "        if pixel_location - max_distance_from_pixel_loc == -1 * max_distance_from_pixel_loc:\n",
    "            left_array = []\n",
    "        else:\n",
    "            left_array = array[0 : pixel_location]\n",
    "        right_array = array[pixel_location: pixel_location + max_distance_from_pixel_loc]\n",
    "    # If the pixel's location right side is greater than the row length\n",
    "    elif (pixel_location + max_distance_from_pixel_loc) > (len(array) - 1):\n",
    "        right_array = []\n",
    "        left_array = array[pixel_location - max_distance_from_pixel_loc: pixel_location-1]\n",
    "    # If the pixel location is the middle of the image\n",
    "    else: \n",
    "        left_array = array[pixel_location - max_distance_from_pixel_loc: pixel_location]\n",
    "        right_array = array[pixel_location + 1 : pixel_location + 1 + max_distance_from_pixel_loc]\n",
    "    # Appends the arrays to a final array which is returned\n",
    "    left_and_right.append(left_array)\n",
    "    left_and_right.append(right_array)\n",
    "    return left_and_right\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithm(new_image_array, b, pixel_tolerance ):\n",
    "    '''\n",
    "    This function takes in:\n",
    "        A 2D array (new_image_array); a background value (b), and a pixel tolerance (pixel_tolerance)\n",
    "    This function:\n",
    "        This loops through the image and determines the percentage change of the left and right side array of the corresponding\n",
    "        pixel. It then determines if this pixel should be changed or set to 0. This function aims to make continous axon\n",
    "        fragment lines\n",
    "    This function returns:\n",
    "        A 2D array which is process array.\n",
    "    '''\n",
    "   \n",
    "    n = pixel_tolerance #pixels away no longer count maximum values\n",
    "    mean_of_background = b\n",
    "    non_empty_row = 0\n",
    "\n",
    "    for i in range(len(new_image_array) - 1): ## Loops through the rows\n",
    "        # print(f\"row mean: {np.mean(new_image_array[i])}\")\n",
    "        if np.mean(new_image_array[i]) > mean_of_background: ## This is how I determine if a row is important (contains potential axons)\n",
    "            # print(\"passed mean test\")\n",
    "            non_empty_row +=1 ## Increments the row count\n",
    "\n",
    "            if non_empty_row != 1 : ## want to leave first row untouched, just want to load it                \n",
    "                for j in range(len(new_image_array[i] - 1)): ## Loops through the columns\n",
    "                    splitted_array = split_array(new_image_array[i-1], j, n) ## Checks the row above and splits the array into the left and right\n",
    "                    combined_val = 0 # Value to calculate the combined value\n",
    "                    left_side_boolean = False\n",
    "                    right_side_boolean = False\n",
    "                    for k in range(len(splitted_array)): # Loops through the array (size of 2)\n",
    "                        if percentage_change(new_image_array[i][j], np.mean(splitted_array[k])) == True: ## If the pixel value at the specific pixel location meets the minimum threshold change \n",
    "                            combined_val += np.mean(splitted_array[k]) # Updates combined value\n",
    "                            if k == 0:\n",
    "                                left_side_boolean = True\n",
    "                            if k == 1:\n",
    "                                right_side_boolean = True\n",
    "                        if k == 1:\n",
    "\n",
    "                            if left_side_boolean == True and right_side_boolean == True :\n",
    "                                new_image_array[i][j] = combined_val # Sets the original array value\n",
    "                                combined_val = 0\n",
    "                            elif((left_side_boolean == False and right_side_boolean == True) or\n",
    "                                         (left_side_boolean == True and right_side_boolean == False)):\n",
    "                                new_image_array[i][j] = 0 # Sets the original array value\n",
    "                                combined_val = 0\n",
    "        else:\n",
    "            # print(\"failed mean test\")\n",
    "            non_empty_row = 0 ## Resets it to the \n",
    "    return new_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint16\n",
      "uint16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x286f15550>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "print(test_array.dtype)\n",
    "output_array = test_algorithm(test_array,500, 10 )\n",
    "print(output_array.dtype)\n",
    "\n",
    "# final = output_array * test_array\n",
    "# plt.imshow(output_array)\n",
    "# print(output_array.shape)\n",
    "\n",
    "\n",
    "final = test_algorithm(remove_noise(output_array * test_array),9.9**7, 10 )\n",
    "plt.imshow(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_lines(lines, distance_threshold):\n",
    "    lines = np.squeeze(lines)\n",
    "    lines = lines.tolist()\n",
    "\n",
    "    # print (f\"lines after tolist() :{lines}\")\n",
    "    # Helper function to check if the distance between two points is within the threshold\n",
    "    \n",
    "    def is_within_distance(p1, p2, threshold):\n",
    "        distance = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "        return distance <= threshold\n",
    "\n",
    "\n",
    "    # Helper function to merge two lines into one\n",
    "    def merge_two_lines(line1, line2):\n",
    "        return [line1[0], line1[1], line2[2], line2[3]]\n",
    "    \n",
    "    def possible_merges(array,distance_threshold):\n",
    "        for i in range (len(array)-1):\n",
    "            x1,y1,x2,y2 = array[i] ## line one\n",
    "            for j in range(i + 1, len(array)):  # Start from i + 1 to avoid redundant checks\n",
    "                    x3,y3,x4,y4 =array[j]\n",
    "                    if is_within_distance((x2, y2), (x3, y3), distance_threshold) or \\\n",
    "                    is_within_distance((x1, y1), (x4, y4), distance_threshold):\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    while possible_merges(lines, distance_threshold): ## while there are still possible merges\n",
    "        print(len(lines))\n",
    "        for i in range(len(lines)):\n",
    "            x1, y1, x2, y2 = lines[i] ## gets line 1 \n",
    "            for j in range (len(lines)):\n",
    "                merged = False\n",
    "                if j != i:\n",
    "                    x3, y3, x4, y4 = lines[j] ## gets line 2\n",
    "                    if is_within_distance((x2, y2), (x3, y3), distance_threshold) or \\\n",
    "                    is_within_distance((x1, y1), (x4, y4), distance_threshold) : ## end and start\n",
    "                        merged_line = merge_two_lines([x1, y1, x2, y2], [x4, y4, x3, y3]) ## merge the lines\n",
    "                        lines.pop(j)\n",
    "                        lines.pop(i)\n",
    "                        lines.append(merged_line)\n",
    "                        merged = True\n",
    "                        break\n",
    "            if merged:\n",
    "                print(\"merged\")\n",
    "                print(f\"i: {i}\")\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell below aims to detect axon fragments(continous lines) to then be able to measure them after this cell.\n",
    "##WIP: Currently not working, overexposing the image.\n",
    "def detect_lines (image_array):\n",
    "    \n",
    "    min_16bit = 0\n",
    "    max_16bit = (2**16)-1\n",
    "\n",
    "    min = 7.0 * (10**3)\n",
    "    max = 8.0 * (10**3)\n",
    "\n",
    "    normalized_min = ((min - min_16bit) / (max_16bit - min_16bit)) * 255\n",
    "    normalized_max = ((max - min_16bit) / (max_16bit - min_16bit)) * 255\n",
    "\n",
    "    normalized_image = cv.normalize(image_array, None, 0, 255, cv.NORM_MINMAX).astype(np.uint8)\n",
    "    # plt.imshow(final)\n",
    "    edges = cv.Canny(normalized_image, normalized_min, normalized_max)\n",
    "\n",
    "    # merged_lines = merge_lines(edges,15)  # Merge lines\n",
    "\n",
    "    cdst = cv.cvtColor(edges, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    # cdst = cv.cvtColor(edges, cv.COLOR_GRAY2BGR)\n",
    "    cdstP = np.copy(cdst)\n",
    "\n",
    "    # lines = cv.HoughLines(edges,1, np.pi / 180, 200)\n",
    "\n",
    "    linesP = cv.HoughLinesP(edges, 1, np.pi / 180, 50, None, 0, 15)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(linesP)\n",
    "    \n",
    "    if isinstance(linesP, np.ndarray):\n",
    "        print(\"linesP is a NumPy array.\")\n",
    "        print(f\"before merge_lines: {linesP}\")\n",
    "    else:\n",
    "        print(\"linesP is not a NumPy array.\")\n",
    "        \n",
    "    merged_lines = merge_lines(linesP, 15)  # Merge lines\n",
    "\n",
    "    def calculate_line_lengths(lines):\n",
    "        lengths = np.sqrt((lines[:, 2] - lines[:, 0])**2 + (lines[:, 3] - lines[:, 1])**2)\n",
    "        return lengths\n",
    "    \n",
    "    def analyze_line_lengths(lengths):\n",
    "        mean_length = np.mean(lengths)\n",
    "        median_length = np.median(lengths)\n",
    "        std_dev = np.std(lengths)\n",
    "        quantiles = np.percentile(lengths, [25, 50, 75])\n",
    "    \n",
    "        stats = {\n",
    "            'mean': mean_length,\n",
    "            'median': median_length,\n",
    "            'std_dev': std_dev,\n",
    "            'quantiles': quantiles\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    line_lengths = calculate_line_lengths(merged_lines)\n",
    "    print(f\"Line lengths: {line_lengths}\")\n",
    "\n",
    "    # Analyze lengths\n",
    "    stats = analyze_line_lengths(line_lengths)\n",
    "    print(f\"Mean length: {stats['mean']}\")\n",
    "    print(f\"Median length: {stats['median']}\")\n",
    "    print(f\"Standard deviation: {stats['std_dev']}\")\n",
    "    print(f\"Quantiles (25th, 50th, 75th): {stats['quantiles']}\")\n",
    "\n",
    "    # Count the number of lines\n",
    "    num_lines = len(merged_lines)\n",
    "    print(f\"Number of lines: {num_lines}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # cv.imshow(\"Source\", image_array)\n",
    "    # cv.imshow(\"Detected Lines (in red) - Standard Hough Line Transform\", cdst)\n",
    "    # cv.imshow(\"Detected Lines (in red) - Probabilistic Line Transform\", cdstP)\n",
    "    # print(f\"Number of lines detected: {line_count}\")\n",
    "    # print(f\"Lengths of detected lines: {line_lengths}\")\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow( image_array)\n",
    "    # plt.figure()\n",
    "    # plt.imshow( cdst)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cdstP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linesP is a NumPy array.\n",
      "before merge_lines: [[[ 617 1897  623 1826]]\n",
      "\n",
      " [[ 636 1701  642 1632]]\n",
      "\n",
      " [[ 724  628  741  432]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 757  569  757  564]]\n",
      "\n",
      " [[ 390 1200  391 1197]]\n",
      "\n",
      " [[ 801  529  802  517]]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m detect_lines(final)\n",
      "Cell \u001b[0;32mIn[65], line 38\u001b[0m, in \u001b[0;36mdetect_lines\u001b[0;34m(image_array)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlinesP is not a NumPy array.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m merged_lines \u001b[39m=\u001b[39m merge_lines(linesP, \u001b[39m15\u001b[39m)  \u001b[39m# Merge lines\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_line_lengths\u001b[39m(lines):\n\u001b[1;32m     41\u001b[0m     lengths \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt((lines[:, \u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m lines[:, \u001b[39m0\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m (lines[:, \u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m lines[:, \u001b[39m1\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 69\u001b[0m, in \u001b[0;36mmerge_lines\u001b[0;34m(lines, distance_threshold)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m# Main loop\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mwhile\u001b[39;00m possible_merges(lines, distance_threshold):\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m merge_lines_once(lines, distance_threshold):\n\u001b[1;32m     70\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m lines\n",
      "Cell \u001b[0;32mIn[64], line 58\u001b[0m, in \u001b[0;36mmerge_lines.<locals>.merge_lines_once\u001b[0;34m(lines, distance_threshold)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mwhile\u001b[39;00m j \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(lines):\n\u001b[1;32m     56\u001b[0m     x3, y3, x4, y4 \u001b[39m=\u001b[39m lines[j]\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m is_within_distance((x2, y2), (x3, y3), distance_threshold) \u001b[39mor\u001b[39;00m \\\n\u001b[0;32m---> 58\u001b[0m        is_within_distance((x1, y1), (x4, y4), distance_threshold):\n\u001b[1;32m     59\u001b[0m         merged_line \u001b[39m=\u001b[39m merge_two_lines([x1, y1, x2, y2], [x4, y4, x3, y3])\n\u001b[1;32m     60\u001b[0m         lines[i] \u001b[39m=\u001b[39m merged_line\n",
      "Cell \u001b[0;32mIn[64], line 9\u001b[0m, in \u001b[0;36mmerge_lines.<locals>.is_within_distance\u001b[0;34m(p1, p2, threshold)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_within_distance\u001b[39m(p1, p2, threshold):\n\u001b[0;32m----> 9\u001b[0m     distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(np\u001b[39m.\u001b[39marray(p1) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39marray(p2))\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m distance \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m threshold\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "detect_lines(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
